"""
geospatial_processing.py
"""

import geopandas as gpd
import pandas as pd
import unicodedata


def normalize(text):
    """Remove accents and uppercase for stable merges."""
    if pd.isna(text):
        return text
    text = text.lower()
    text = unicodedata.normalize("NFKD", text).encode("ascii", "ignore").decode()
    return text.strip()


def load_colonias(geojson_path):
    gdf = gpd.read_file(geojson_path)
    gdf = gdf[["ID", "NOMUT", "NOMDT", "geometry"]]
    colnames = ["colonia_id", "colonia_name", "alcaldia", "geometry"]
    gdf.columns = colnames
    return calculate_area_density(gdf)

def calculate_area_density(gdf):
    gdf_proj = gdf.to_crs(epsg=32614)  # UTM zone for CDMX

    # ðŸ”¹ area-based population proxy
    gdf_proj["area_km2"] = gdf_proj.geometry.area / 1e6
    gdf_proj["pop_weight"] = (1 / gdf_proj["area_km2"]) ** 0.5
    gdf_proj["pop_weight"] /= gdf_proj["pop_weight"].sum()

    #ðŸ”¹ back to lat/lon for plotting
    return gdf_proj.to_crs(epsg=4326)


def aggregate_risk(panel_df, students_df, colonias_df):
    """Correct aggregation of dropout risk by colonia."""

    # 1) Compute per-student dropout (0 or 1)
    student_dropout = panel_df.groupby("student_id")["dropped"].max().reset_index()
    student_dropout.columns = ["student_id", "ever_dropped"]

    # 2) Attach dropout to students
    merged = students_df.merge(student_dropout, on="student_id", how="left")

    # 3) Compute average risk per colonia
    risk = merged.groupby("colonia_id")["ever_dropped"].mean().reset_index()

    # 4) Merge with full colonia list (so holes disappear)
    risk_full = colonias_df.merge(risk, on="colonia_id", how="left")

    # colonias with no students â†’ assign 0 (or NaN if you prefer)
    risk_full["ever_dropped"] = risk_full["ever_dropped"].fillna(0)

    return risk_full

